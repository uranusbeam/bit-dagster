resources:
  db_info:
    config:
      db_name:
        env: REDSHIFT_DB
      hostname:
        env: REDSHIFT_ENDPOINT
      port:
        env: REDSHIFT_PORT
      password:
        env: REDSHIFT_PASSWORD
      username:
        env: REDSHIFT_USERNAME
      s3_temp_dir: "dagster-scratch-80542c2"
  file_cache:
    config:
      bucket: "dagster-scratch-80542c2"
      key: "airline-demo"
  pyspark:
    config:
      cluster_id:
        env: EMR_CLUSTER_ID
      pipeline_file: "dagster_examples/airline_demo/pipelines.py"
      pipeline_fn_name: "airline_demo_ingest_pipeline"
      region_name: "us-west-1"
      staging_bucket: "dagster-scratch-80542c2"
      spark_config:
        spark:
          jars:
            packages: com.databricks:spark-avro_2.11:3.0.0,com.databricks:spark-redshift_2.11:2.0.1,com.databricks:spark-csv_2.11:1.5.0,org.postgresql:postgresql:42.2.5,org.apache.hadoop:hadoop-aws:2.6.5,com.amazonaws:aws-java-sdk:1.7.4
